{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/rufaelmarew/Documents/tau/finger_pose_estimation/dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.edf\"\n",
    "leap_path = \"/Users/rufaelmarew/Documents/tau/finger_pose_estimation/dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/rufaelmarew/Documents/tau/finger_pose_estimation/dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 135499  =      0.000 ...   541.996 secs...\n",
      "2024-01-02 11:17:25\n"
     ]
    }
   ],
   "source": [
    "def read_emg(path, start_time=None, end_time=None, fs: int=250):\n",
    "\n",
    "    raw = mne.io.read_raw_edf(path, preload=True)\n",
    "\n",
    "    # get header\n",
    "    header = raw.info\n",
    "\n",
    "    if start_time is None:\n",
    "        start_time = header['meas_date']\n",
    "        # convert to pd.datetime from datetime.datetime\n",
    "        start_time = pd.to_datetime(start_time).tz_localize(None)\n",
    "        # remove 2 hours\n",
    "        start_time = start_time - pd.to_timedelta(2, unit='h')\n",
    "        print(start_time)\n",
    "    \n",
    "    #  get annotations\n",
    "    annotations = raw.annotations\n",
    "    annotations.onset = start_time + pd.to_timedelta(annotations.onset, unit='s')\n",
    "    \n",
    "    # get annotations as df\n",
    "    to_append = []\n",
    "    for ind, (i,j) in enumerate(zip(annotations.onset, annotations.description)):\n",
    "        if 'start' in j:\n",
    "            if 'end_' in annotations.description[ind+1]:\n",
    "                new_j = j.replace('start', '').strip('_')\n",
    "                #  add 1 sec ofset to onset and append\n",
    "                offset = pd.to_timedelta(1, unit='s')\n",
    "                to_append.append([annotations.onset[ind]+offset, annotations.onset[ind+1]+offset, new_j])\n",
    "        \n",
    "    ann_df = pd.DataFrame(to_append, columns=['start_time', 'end_time', 'gesture'])\n",
    "    #  if duration is greater than 10 sec, drop\n",
    "    ann_df = ann_df[ann_df['end_time'] - ann_df['start_time'] < pd.to_timedelta(10, unit='s')]\n",
    "\n",
    "\n",
    "    emg_df = raw.to_data_frame()\n",
    "    emg_df['time'] = pd.to_datetime(emg_df['time'], unit='s', origin=start_time)\n",
    "    emg_df.set_index('time', inplace=True)\n",
    "\n",
    "    # start data from first annotation\n",
    "    start_time = ann_df['start_time'].iloc[0]\n",
    "    emg_df = emg_df[start_time:]\n",
    "    \n",
    "    #  resample emg data to fs Hz\n",
    "    emg_df = emg_df.resample(f'{int(1000/fs)}ms', origin='start').mean()\n",
    "\n",
    "    return emg_df, ann_df, header\n",
    "\n",
    "emg_data, ann, header = read_emg(path = data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_leap(path, fs=125):\n",
    "\n",
    "    leap_df = pd.read_csv(path, index_col=False)\n",
    "\n",
    "    # drop null and duplicates\n",
    "    leap_df.dropna(inplace=True)\n",
    "    leap_df.drop_duplicates(inplace=True, subset=['time'])\n",
    "\n",
    "    leap_df['time'] = pd.to_datetime(leap_df['time'])\n",
    "    leap_df['time'] = leap_df['time'].dt.tz_localize(None)\n",
    "    leap_df = leap_df.set_index('time')\n",
    "\n",
    "    # calculate relative position\n",
    "    for i in leap_df.columns:\n",
    "        if 'position_x' in i:\n",
    "            leap_df[i] = leap_df[i] - leap_df['palm_x']\n",
    "        elif 'position_y' in i:\n",
    "            leap_df[i] = leap_df[i] - leap_df['palm_y']\n",
    "        elif 'position_z' in i:\n",
    "            leap_df[i] = leap_df[i] - leap_df['palm_z']\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # leap_df = leap_df.resample(f'{int(1000/fs)}ms', origin='start').ffill()\n",
    "\n",
    "    # valid_columns = build_leap_columns()\n",
    "    # leap_df = leap_df[valid_columns]\n",
    "\n",
    "    return leap_df, None, None\n",
    "\n",
    "leap_data, _, _ = read_leap(leap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = max(min(leap_data.index), min(emg_data.index))\n",
    "end_time = min(max(leap_data.index), max(emg_data.index))\n",
    "\n",
    "leap_data = leap_data.loc[start_time:end_time]\n",
    "emg_data = emg_data.loc[start_time:end_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 25\n",
      "(125809, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5023, 250, 16), (5023,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_windowed_dataset(df, w, s, fs):\n",
    "    # Convert window size and stride from seconds to number of rows\n",
    "    w_rows = int(w * fs)\n",
    "    s_rows = int(s * fs)\n",
    "    print(w_rows, s_rows)\n",
    "    print(df.shape)\n",
    "    data = []\n",
    "    times = []\n",
    "    for i in range(0, len(df) - w_rows, s_rows):\n",
    "        window = df.iloc[i:i+w_rows]\n",
    "        data.append(window.values)\n",
    "        times.append(window.index[-1])\n",
    "\n",
    "    data = np.array(data)\n",
    "    times = np.array(times)\n",
    "\n",
    "    # Reshape data to (N-w)/(S)*W*C\n",
    "    data = data.reshape((-1, w_rows , df.shape[1]))\n",
    "\n",
    "    return data, times\n",
    "\n",
    "data, times = create_windowed_dataset(emg_data, 1, 0.1, fs=250)\n",
    "data.shape, times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threefingers\n"
     ]
    }
   ],
   "source": [
    "# get gesture if time is between start and end time\n",
    "def get_gesture(time, ann_df):\n",
    "    gesture_df = ann_df[(ann_df['start_time'] <= time) & (ann_df['end_time'] >= time)]\n",
    "    if not gesture_df.empty:\n",
    "        return gesture_df['gesture'].iloc[0]\n",
    "    return 'rest'\n",
    "t = get_gesture(times[0], ann)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the leap data that are closest to the times array\n",
    "def find_closest(leap_data, times, annotations):\n",
    "    index = []\n",
    "    gestures = []   \n",
    "    for i in times:\n",
    "        #  find the time indeex closest to i\n",
    "        index.append(leap_data.index.asof(i))\n",
    "        gestures.append(get_gesture(i,annotations))\n",
    "        #  find the gesture closest to i\n",
    "    leap_closest = leap_data.loc[index]\n",
    "    \n",
    "    return leap_closest.to_numpy(), gestures\n",
    "\n",
    "index, gestures = find_closest(leap_data, times, ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5023, 250, 16), (5023, 147), 5023)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, index.shape, len(gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rest            2527\n",
       "twofingers       253\n",
       "abduction        252\n",
       "kaf              252\n",
       "tet              251\n",
       "het              251\n",
       "fist             250\n",
       "bet              250\n",
       "gimel            248\n",
       "nun              248\n",
       "threefingers     241\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value couts for each gesture\n",
    "def get_gesture_counts(gestures):\n",
    "    return pd.Series(gestures).value_counts()\n",
    "get_gesture_counts(gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "def read_dirs(data_path):\n",
    "    if not os.path.isdir(data_path):\n",
    "        raise ValueError(f'{data_path} is not a directory')\n",
    "\n",
    "    # Traverse through all the directories and read the data\n",
    "    all_files = [f for f in glob.glob(os.path.join(data_path, '**/*'), recursive=True) if os.path.splitext(f)[1] in ['.edf', '.csv']]\n",
    "\n",
    "    # Separate .edf and .csv files\n",
    "    edf_files = sorted([file for file in all_files if file.endswith('.edf')])\n",
    "    csv_files = sorted([file for file in all_files if file.endswith('.csv')])\n",
    "\n",
    "    return edf_files, csv_files\n",
    "\n",
    "edf_files, csv_files = read_dirs('../dataset/FPE/')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../dataset/FPE/S1/p1/fpe_pos1_001_S1_rep0_BT.csv',\n",
       " '../dataset/FPE/S1/p2/fpe_pos2_001_S1_rep0_BT.csv',\n",
       " '../dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.csv',\n",
       " '../dataset/FPE/S1/p4/fpe_pos4_001_S1_rep0_BT.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Dataset Class test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA:\n",
      "  EMG:\n",
      "    BUFF_LEN: 0\n",
      "    FEATURE_EXTRACTOR: RMS\n",
      "    HIGH_FREQ: 400\n",
      "    LOW_FREQ: 10\n",
      "    NORMALIZATION: max\n",
      "    NOTCH_FREQ: 50\n",
      "    NUM_CHANNELS: 16\n",
      "    Q: 30\n",
      "    SAMPLING_RATE: 250\n",
      "    WINDOW_SIZE: 100\n",
      "    WINDOW_STRIDE: 50\n",
      "  EXP_SETUP: exp0\n",
      "  FILTER_DATA: True\n",
      "  ICA: False\n",
      "  LABEL_COLUMNS: ['Thumb_Metacarpal_position_x', 'Thumb_Metacarpal_position_y', 'Thumb_Metacarpal_position_z', 'Thumb_Proximal_position_x', 'Thumb_Proximal_position_y', 'Thumb_Proximal_position_z', 'Thumb_Intermediate_position_x', 'Thumb_Intermediate_position_y', 'Thumb_Intermediate_position_z', 'Thumb_Distal_position_x', 'Thumb_Distal_position_y', 'Thumb_Distal_position_z', 'Index_Metacarpal_position_x', 'Index_Metacarpal_position_y', 'Index_Metacarpal_position_z', 'Index_Proximal_position_x', 'Index_Proximal_position_y', 'Index_Proximal_position_z', 'Index_Intermediate_position_x', 'Index_Intermediate_position_y', 'Index_Intermediate_position_z', 'Index_Distal_position_x', 'Index_Distal_position_y', 'Index_Distal_position_z', 'Middle_Metacarpal_position_x', 'Middle_Metacarpal_position_y', 'Middle_Metacarpal_position_z', 'Middle_Proximal_position_x', 'Middle_Proximal_position_y', 'Middle_Proximal_position_z', 'Middle_Intermediate_position_x', 'Middle_Intermediate_position_y', 'Middle_Intermediate_position_z', 'Middle_Distal_position_x', 'Middle_Distal_position_y', 'Middle_Distal_position_z', 'Ring_Metacarpal_position_x', 'Ring_Metacarpal_position_y', 'Ring_Metacarpal_position_z', 'Ring_Proximal_position_x', 'Ring_Proximal_position_y', 'Ring_Proximal_position_z', 'Ring_Intermediate_position_x', 'Ring_Intermediate_position_y', 'Ring_Intermediate_position_z', 'Ring_Distal_position_x', 'Ring_Distal_position_y', 'Ring_Distal_position_z', 'Pinky_Metacarpal_position_x', 'Pinky_Metacarpal_position_y', 'Pinky_Metacarpal_position_z', 'Pinky_Proximal_position_x', 'Pinky_Proximal_position_y', 'Pinky_Proximal_position_z', 'Pinky_Intermediate_position_x', 'Pinky_Intermediate_position_y', 'Pinky_Intermediate_position_z', 'Pinky_Distal_position_x', 'Pinky_Distal_position_y', 'Pinky_Distal_position_z', 'Thumb_Metacarpal_rotation_w', 'Thumb_Proximal_rotation_w', 'Thumb_Intermediate_rotation_w', 'Thumb_Distal_rotation_w', 'Index_Metacarpal_rotation_w', 'Index_Proximal_rotation_w', 'Index_Intermediate_rotation_w', 'Index_Distal_rotation_w', 'Middle_Metacarpal_rotation_w', 'Middle_Proximal_rotation_w', 'Middle_Intermediate_rotation_w', 'Middle_Distal_rotation_w', 'Ring_Metacarpal_rotation_w', 'Ring_Proximal_rotation_w', 'Ring_Intermediate_rotation_w', 'Ring_Distal_rotation_w', 'Pinky_Metacarpal_rotation_w', 'Pinky_Proximal_rotation_w', 'Pinky_Intermediate_rotation_w', 'Pinky_Distal_rotation_w']\n",
      "  LABEL_PATH: finger_pose_estimation/dataset/label_2023-10-02_15-24-12_YH_lab_R.csv\n",
      "  MANUS:\n",
      "    KEY_POINTS: []\n",
      "    NUM_JOINTS: 20\n",
      "    SAMPLING_RATE: 250\n",
      "  PATH: ../dataset/FPE/S1\n",
      "  SEGMENT_LENGTH: 200\n",
      "  STRIDE: 5\n",
      "  VIDEO:\n",
      "    NUM_CHANNELS: 3\n",
      "    SAMPLING_RATE: 30\n",
      "DEBUG: False\n",
      "MODEL:\n",
      "  NAME: transformer\n",
      "SOLVER:\n",
      "  BATCH_SIZE: 32\n",
      "  CHECKPOINT_PERIOD: 10\n",
      "  DEVICE: cuda\n",
      "  LOG_DIR: ./outputs\n",
      "  LR: 0.001\n",
      "  METRIC: mse\n",
      "  MOMENTUM: 0.9\n",
      "  NUM_EPOCHS: 100\n",
      "  NUM_WORKERS: 4\n",
      "  OPTIMIZER: Adam\n",
      "  PATIENCE: 5\n",
      "  PIN_MEMORY: True\n",
      "  PRETRAINED_PATH: model.pth\n",
      "  PRINT_FREQ: 10\n",
      "  SEED: 42\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "VISUALIZE:\n",
      "  PORT: 9000\n",
      "Reading data from ../dataset/FPE/S1/p1\n",
      "Reading data from ../dataset/FPE/S1/p2\n",
      "Reading data from ../dataset/FPE/S1/p3\n",
      "Reading data from ../dataset/FPE/S1/p1/fpe_pos1_001_S1_rep0_BT.edf and ../dataset/FPE/S1/p1/fpe_pos1_001_S1_rep0_BT.csv\n",
      "Reading data from ../dataset/FPE/S1/p2/fpe_pos2_001_S1_rep0_BT.edf and ../dataset/FPE/S1/p2/fpe_pos2_001_S1_rep0_BT.csv\n",
      "Reading data from ../dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.edf and ../dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.csv\n",
      "2024-01-02 10:11:29\n",
      "2024-01-02 09:52:23\n",
      "2024-01-02 11:17:25\n",
      "Time taken to create windowed dataset: 8.495528936386108\n",
      "Filtering data...\n",
      "Time taken to create windowed dataset: 22.434815168380737\n",
      "Time taken to create windowed dataset: 11.807420015335083\n",
      "Filtering data...\n",
      "Filtering data...\n",
      "data shape:  (67803, 200, 16)\n",
      "Reading data from ../dataset/FPE/S1/p4\n",
      "Reading data from ../dataset/FPE/S1/p4/fpe_pos4_001_S1_rep0_BT.edf and ../dataset/FPE/S1/p4/fpe_pos4_001_S1_rep0_BT.csv\n",
      "2024-01-02 11:30:02\n",
      "Time taken to create windowed dataset: 10.723649024963379\n",
      "Filtering data...\n",
      "data shape:  (25136, 200, 16)\n",
      "Runnig experiment setup exp1 with \n",
      "\n",
      "train: ['S1/p1', 'S1/p2', 'S1/p3'] \n",
      "\n",
      "and test: ['S1/p4']\n",
      "Number of training examples: 67803\n",
      "Number of validation examples: 67803\n",
      "Number of test examples: 25136\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'label_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m cfg\u001b[38;5;241m.\u001b[39mDATA\u001b[38;5;241m.\u001b[39mSTRIDE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     11\u001b[0m cfg\u001b[38;5;241m.\u001b[39mDATA\u001b[38;5;241m.\u001b[39mEXP_SETUP \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmake_exp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tau/finger_pose_estimation/notebooks/../data/default.py:88\u001b[0m, in \u001b[0;36mmake_exp_dataset\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of validation examples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of test examples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_columns\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'label_columns'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import cfg\n",
    "from data import make_dataset, make_exp_dataset\n",
    "print(cfg)\n",
    "cfg.DEBUG = False\n",
    "cfg.DATA.PATH = '../dataset/FPE/S1'\n",
    "cfg.DATA.EMG.SAMPLING_RATE = 250\n",
    "cfg.DATA.SEGMENT_LENGTH = 200\n",
    "cfg.DATA.STRIDE = 5\n",
    "cfg.DATA.EXP_SETUP = 'exp1'\n",
    "\n",
    "\n",
    "dataset = make_exp_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25136, 200, 16]),\n",
       " torch.Size([25136, 200, 16]),\n",
       " torch.Size([67803, 200, 16]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].dataset.data.shape, dataset['val'].dataset.data.shape, dataset['test'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['./datasets/FPE/S1/p1', './datasets/FPE/S1/p2', './datasets/FPE/S1/p3'],\n",
       " ['./datasets/FPE/S1/p4'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from config import cfg\n",
    "import os\n",
    "print(os.sep)\n",
    "exp_setups = {\n",
    "    'exp0': None,\n",
    "\n",
    "    'exp1': {\n",
    "        'train': [f\"S1{os.sep}p1\"],\n",
    "        'test': [f'S1{os.sep}p2']\n",
    "    },\n",
    "\n",
    "    'exp2': {\n",
    "        'train': [f'S1{os.sep}p1', f'S1{os.sep}p2', f'S1{os.sep}p3'],\n",
    "        'test': [f'S1{os.sep}p4'] \n",
    "    },\n",
    "}\n",
    "\n",
    "def get_dirs_for_exp(cfg):\n",
    "\n",
    "    data_path = \"./datasets/FPE\"\n",
    "    # if cfg.DATA.EXP_SETUP not in exp_setups.keys():\n",
    "    #     raise ValueError(f'Invalid experiment setup {cfg.DATA.EXP_SETUP}')\n",
    "    \n",
    "    train_dirs = []\n",
    "    test_dirs = []\n",
    "\n",
    "    for dir in exp_setups['exp2']['train']:\n",
    "        train_dirs.append(os.path.join(data_path, dir))\n",
    "\n",
    "    for dir in exp_setups['exp2']['test']:\n",
    "        test_dirs.append(os.path.join(data_path, dir))\n",
    "\n",
    "    return train_dirs, test_dirs\n",
    "get_dirs_for_exp(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getitems__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_is_protocol',\n",
       " 'dataset',\n",
       " 'indices']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
