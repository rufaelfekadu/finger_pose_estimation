{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/rufaelmarew/Documents/tau/finger_pose_estimation/dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.edf\"\n",
    "leap_path = \"/Users/rufaelmarew/Documents/tau/finger_pose_estimation/dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/rufaelmarew/Documents/tau/finger_pose_estimation/dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 135499  =      0.000 ...   541.996 secs...\n",
      "2024-01-02 11:17:25\n"
     ]
    }
   ],
   "source": [
    "def read_emg(path, start_time=None, end_time=None, fs: int=250):\n",
    "\n",
    "    raw = mne.io.read_raw_edf(path, preload=True)\n",
    "\n",
    "    # get header\n",
    "    header = raw.info\n",
    "\n",
    "    if start_time is None:\n",
    "        start_time = header['meas_date']\n",
    "        # convert to pd.datetime from datetime.datetime\n",
    "        start_time = pd.to_datetime(start_time).tz_localize(None)\n",
    "        # remove 2 hours\n",
    "        start_time = start_time - pd.to_timedelta(2, unit='h')\n",
    "        print(start_time)\n",
    "    \n",
    "    #  get annotations\n",
    "    annotations = raw.annotations\n",
    "    annotations.onset = start_time + pd.to_timedelta(annotations.onset, unit='s')\n",
    "    \n",
    "    # get annotations as df\n",
    "    to_append = []\n",
    "    for ind, (i,j) in enumerate(zip(annotations.onset, annotations.description)):\n",
    "        if 'start' in j:\n",
    "            if 'end_' in annotations.description[ind+1]:\n",
    "                new_j = j.replace('start', '').strip('_')\n",
    "                #  add 1 sec ofset to onset and append\n",
    "                offset = pd.to_timedelta(1, unit='s')\n",
    "                to_append.append([annotations.onset[ind]+offset, annotations.onset[ind+1]+offset, new_j])\n",
    "        \n",
    "    ann_df = pd.DataFrame(to_append, columns=['start_time', 'end_time', 'gesture'])\n",
    "    #  if duration is greater than 10 sec, drop\n",
    "    ann_df = ann_df[ann_df['end_time'] - ann_df['start_time'] < pd.to_timedelta(10, unit='s')]\n",
    "\n",
    "\n",
    "    emg_df = raw.to_data_frame()\n",
    "    emg_df['time'] = pd.to_datetime(emg_df['time'], unit='s', origin=start_time)\n",
    "    emg_df.set_index('time', inplace=True)\n",
    "\n",
    "    # start data from first annotation\n",
    "    start_time = ann_df['start_time'].iloc[0]\n",
    "    emg_df = emg_df[start_time:]\n",
    "    \n",
    "    #  resample emg data to fs Hz\n",
    "    emg_df = emg_df.resample(f'{int(1000/fs)}ms', origin='start').mean()\n",
    "\n",
    "    return emg_df, ann_df, header\n",
    "\n",
    "emg_data, ann, header = read_emg(path = data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_leap(path, fs=125):\n",
    "\n",
    "    leap_df = pd.read_csv(path, index_col=False)\n",
    "\n",
    "    # drop null and duplicates\n",
    "    leap_df.dropna(inplace=True)\n",
    "    leap_df.drop_duplicates(inplace=True, subset=['time'])\n",
    "\n",
    "    leap_df['time'] = pd.to_datetime(leap_df['time'])\n",
    "    leap_df['time'] = leap_df['time'].dt.tz_localize(None)\n",
    "    leap_df = leap_df.set_index('time')\n",
    "\n",
    "    # calculate relative position\n",
    "    for i in leap_df.columns:\n",
    "        if 'position_x' in i:\n",
    "            leap_df[i] = leap_df[i] - leap_df['palm_x']\n",
    "        elif 'position_y' in i:\n",
    "            leap_df[i] = leap_df[i] - leap_df['palm_y']\n",
    "        elif 'position_z' in i:\n",
    "            leap_df[i] = leap_df[i] - leap_df['palm_z']\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # leap_df = leap_df.resample(f'{int(1000/fs)}ms', origin='start').ffill()\n",
    "\n",
    "    # valid_columns = build_leap_columns()\n",
    "    # leap_df = leap_df[valid_columns]\n",
    "\n",
    "    return leap_df, None, None\n",
    "\n",
    "leap_data, _, _ = read_leap(leap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = max(min(leap_data.index), min(emg_data.index))\n",
    "end_time = min(max(leap_data.index), max(emg_data.index))\n",
    "\n",
    "leap_data = leap_data.loc[start_time:end_time]\n",
    "emg_data = emg_data.loc[start_time:end_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 25\n",
      "(125809, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5023, 250, 16), (5023,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_windowed_dataset(df, w, s, fs):\n",
    "    # Convert window size and stride from seconds to number of rows\n",
    "    w_rows = int(w * fs)\n",
    "    s_rows = int(s * fs)\n",
    "    print(w_rows, s_rows)\n",
    "    print(df.shape)\n",
    "    data = []\n",
    "    times = []\n",
    "    for i in range(0, len(df) - w_rows, s_rows):\n",
    "        window = df.iloc[i:i+w_rows]\n",
    "        data.append(window.values)\n",
    "        times.append(window.index[-1])\n",
    "\n",
    "    data = np.array(data)\n",
    "    times = np.array(times)\n",
    "\n",
    "    # Reshape data to (N-w)/(S)*W*C\n",
    "    data = data.reshape((-1, w_rows , df.shape[1]))\n",
    "\n",
    "    return data, times\n",
    "\n",
    "data, times = create_windowed_dataset(emg_data, 1, 0.1, fs=250)\n",
    "data.shape, times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threefingers\n"
     ]
    }
   ],
   "source": [
    "# get gesture if time is between start and end time\n",
    "def get_gesture(time, ann_df):\n",
    "    gesture_df = ann_df[(ann_df['start_time'] <= time) & (ann_df['end_time'] >= time)]\n",
    "    if not gesture_df.empty:\n",
    "        return gesture_df['gesture'].iloc[0]\n",
    "    return 'rest'\n",
    "t = get_gesture(times[0], ann)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the leap data that are closest to the times array\n",
    "def find_closest(leap_data, times, annotations):\n",
    "    index = []\n",
    "    gestures = []   \n",
    "    for i in times:\n",
    "        #  find the time indeex closest to i\n",
    "        index.append(leap_data.index.asof(i))\n",
    "        gestures.append(get_gesture(i,annotations))\n",
    "        #  find the gesture closest to i\n",
    "    leap_closest = leap_data.loc[index]\n",
    "    \n",
    "    return leap_closest.to_numpy(), gestures\n",
    "\n",
    "index, gestures = find_closest(leap_data, times, ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5023, 250, 16), (5023, 147), 5023)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, index.shape, len(gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rest            2527\n",
       "twofingers       253\n",
       "abduction        252\n",
       "kaf              252\n",
       "tet              251\n",
       "het              251\n",
       "fist             250\n",
       "bet              250\n",
       "gimel            248\n",
       "nun              248\n",
       "threefingers     241\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value couts for each gesture\n",
    "def get_gesture_counts(gestures):\n",
    "    return pd.Series(gestures).value_counts()\n",
    "get_gesture_counts(gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def read_dirs(data_path):\n",
    "    if not os.path.isdir(data_path):\n",
    "        raise ValueError(f'{data_path} is not a directory')\n",
    "\n",
    "    # Traverse through all the directories and read the data\n",
    "    all_files = glob.glob(os.path.join(data_path, '**/*'), recursive=True)\n",
    "\n",
    "    # Separate .edf and .csv files\n",
    "    edf_files = [file for file in all_files if file.endswith('.edf')]\n",
    "    csv_files = [file for file in all_files if file.endswith('.csv')]\n",
    "\n",
    "    return edf_files, csv_files\n",
    "\n",
    "edf_files, csv_files = read_dirs('../dataset/FPE/')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../dataset/FPE/S1/p1/fpe_pos1_001_S1_rep0_BT.edf',\n",
       " '../dataset/FPE/S1/p1/fpe_pos1_001_S1_rep0_BT.csv')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf_files [1], csv_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA:\n",
      "  EMG:\n",
      "    BUFF_LEN: 0\n",
      "    FEATURE_EXTRACTOR: RMS\n",
      "    HIGH_FREQ: 400\n",
      "    LOW_FREQ: 10\n",
      "    NORMALIZATION: max\n",
      "    NOTCH_FREQ: 50\n",
      "    NUM_CHANNELS: 16\n",
      "    Q: 30\n",
      "    SAMPLING_RATE: 150\n",
      "    WINDOW_SIZE: 100\n",
      "    WINDOW_STRIDE: 50\n",
      "  FILTER_DATA: True\n",
      "  LABEL_PATH: finger_pose_estimation/dataset/label_2023-10-02_15-24-12_YH_lab_R.csv\n",
      "  MANUS:\n",
      "    KEY_POINTS: []\n",
      "    NUM_JOINTS: 20\n",
      "    SAMPLING_RATE: 250\n",
      "  PATH: finger_pose_estimation/dataset/data_2023-10-02 14-59-55-627.edf\n",
      "  SEGMENT_LENGTH: 150\n",
      "  STRIDE: 1\n",
      "  VIDEO:\n",
      "    NUM_CHANNELS: 3\n",
      "    SAMPLING_RATE: 30\n",
      "DEBUG: True\n",
      "MODEL:\n",
      "  NAME: transformer\n",
      "SOLVER:\n",
      "  BATCH_SIZE: 32\n",
      "  CHECKPOINT_PERIOD: 10\n",
      "  DEVICE: cuda\n",
      "  LOG_DIR: ./outputs\n",
      "  LR: 0.001\n",
      "  METRIC: mse\n",
      "  MOMENTUM: 0.9\n",
      "  NUM_EPOCHS: 100\n",
      "  NUM_WORKERS: 4\n",
      "  OPTIMIZER: Adam\n",
      "  PATIENCE: 5\n",
      "  PIN_MEMORY: True\n",
      "  PRETRAINED_PATH: model.pth\n",
      "  PRINT_FREQ: 10\n",
      "  SEED: 42\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "VISUALIZE:\n",
      "  PORT: 9000\n",
      "Reading data from ../dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.edf and ../dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.csv\n",
      "Extracting EDF parameters from /Users/rufaelmarew/Documents/tau/finger_pose_estimation/dataset/FPE/S1/p3/fpe_pos3_001_S1_rep0_BT.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 135499  =      0.000 ...   541.996 secs...\n",
      "2024-01-02 11:17:25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m cfg\u001b[38;5;241m.\u001b[39mDATA\u001b[38;5;241m.\u001b[39mSEGMENT_LENGTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     10\u001b[0m cfg\u001b[38;5;241m.\u001b[39mDATA\u001b[38;5;241m.\u001b[39mSTRIDE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 13\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/tau/finger_pose_estimation/notebooks/../data/default.py:46\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m: cfg\u001b[38;5;241m.\u001b[39mDATA\u001b[38;5;241m.\u001b[39mPATH,\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_len\u001b[39m\u001b[38;5;124m'\u001b[39m:cfg\u001b[38;5;241m.\u001b[39mDATA\u001b[38;5;241m.\u001b[39mSEGMENT_LENGTH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotch_freq\u001b[39m\u001b[38;5;124m'\u001b[39m:cfg\u001b[38;5;241m.\u001b[39mDATA\u001b[38;5;241m.\u001b[39mEMG\u001b[38;5;241m.\u001b[39mNOTCH_FREQ,\n\u001b[1;32m     45\u001b[0m     }\n\u001b[0;32m---> 46\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mEMGLeap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mica\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/Documents/tau/finger_pose_estimation/notebooks/../data/EMGLeap.py:47\u001b[0m, in \u001b[0;36mEMGLeap.__init__\u001b[0;34m(self, ica, kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(edf_files)):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReading data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medf_files[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_files[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     data, label, gestures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43medf_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "File \u001b[0;32m~/Documents/tau/finger_pose_estimation/notebooks/../data/EMGLeap.py:103\u001b[0m, in \u001b[0;36mEMGLeap.prepare_data\u001b[0;34m(self, data_path, label_path)\u001b[0m\n\u001b[1;32m    100\u001b[0m label, gestures \u001b[38;5;241m=\u001b[39m find_closest(label, label_index, annotations)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# normalize the data\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_and_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# convert to tensor\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# self.data = torch.tensor(self.data, dtype=torch.float32)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# self.label = torch.tensor(self.label, dtype=torch.float32)\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, label, gestures\n",
      "File \u001b[0;32m~/Documents/tau/finger_pose_estimation/notebooks/../data/EMGLeap.py:111\u001b[0m, in \u001b[0;36mEMGLeap.normalize_and_filter\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize_and_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 111\u001b[0m     N, C, L \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    112\u001b[0m     data_sliced \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, L)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# normalize the data\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import cfg\n",
    "from data import make_dataset\n",
    "print(cfg)\n",
    "cfg.DEBUG = False\n",
    "cfg.DATA.PATH = '../dataset/FPE/S1/p3'\n",
    "cfg.DATA.EMG.SAMPLING_RATE = 250\n",
    "cfg.DATA.SEGMENT_LENGTH = 100\n",
    "cfg.DATA.STRIDE = 10\n",
    "\n",
    "\n",
    "dataset = make_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
